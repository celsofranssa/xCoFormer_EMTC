name: Si_LRG_BERT

type: single

encoder:
  _target_: source.encoder.BertEncoder.BertEncoder
  architecture: bert-large-cased
  output_attentions: False

hidden_size: 1024
text_max_length: ${data.text_max_length}
labels_max_length: ${data.labels_max_length}
max_labels: ${data.max_labels}

batch_size: ${data.batch_size}

tokenizer:
  architecture: ${model.encoder.architecture}


lr: 5e-6
text_lr: 5e-6
label_lr: 5e-6
base_lr: 5e-7
max_lr: 5e-5
weight_decay: 1e-2

loss:
  _target_: source.loss.NTXentLoss.NTXentLoss
  params:
    name: NTXentLoss
    miner:
      relevance_map:
        dir: ${data.dir}
    criterion:
      temperature: 0.07

metric:
  relevance_map:
    dir: ${data.dir}
  num_nearest_neighbors: 10
  max_labels: ${data.max_labels}
  index: ${eval.index}